\documentclass[aoas]{imsart}
%\usepackage{setspace}

\usepackage{dsfont}
\usepackage{amsthm,amsmath,amssymb,natbib}
\RequirePackage[colorlinks,citecolor=blue,urlcolor=blue]{hyperref}
\usepackage{xspace,soul}
\usepackage{graphicx}

\usepackage[margin=1.45in]{geometry}

\startlocaldefs
\newcommand{\blind}{Three anonymous authors}

\newcommand{\Ex}{\mathbb{E}}
\newcommand{\Var}{\text{Var}}
\newcommand{\bp}{\mathbf{p}}

\newcommand{\R}{\textsf{R}\xspace}
\newcommand{\pkg}[1]{\texttt{#1}\xspace}

\newcommand{\greg}[1]{\sethlcolor{yellow}\hl{[GM]: #1}}
\newcommand{\ben}[1]{\sethlcolor{green}\hl{[BB]: #1}}
\newcommand{\mike}[1]{\sethlcolor{cyan}\hl{[ML]: #1}}

\def\balpha{\pmb{\alpha}}
\def\btheta{\pmb{\theta}}
\def\bgamma{\pmb{\gamma}}
\def\btheta{\pmb{\theta}}
\def\bphi{\pmb{\phi}}
\def\bpsi{\pmb{\psi}}
\def\bB{\pmb{B}}
\def\bD{\pmb{D}}
\def\bH{\pmb{H}}
\def\bS{\pmb{S}}
\def\bX{\pmb{X}}

\endlocaldefs



\begin{document}
\SweaveOpts{concordance=TRUE}


\begin{frontmatter}

\title{Rush Independent Passing Player Efficiency Number (RIPPEN)}
\runtitle{RIPPEN}



\author{\fnms{Gregory J.} \snm{Matthews}\corref{}\ead[label=e1]{gmatthews1@luc.edu}}
\address{\printead{e1}}
\affiliation{Skidmore College}

\and
\author{\fnms{Russell} \snm{Cain}\ead[label=e2]{rcain@luc.edu}}
\address{\printead{e2}}
\affiliation{Loyola University Chicago}

\and
\author{\fnms{Donald} \snm{Stolz}\ead[label=e3]{dstolz@luc.edu}}
\address{\printead{e3}}
\affiliation{Loyola University Chicago}

 
\runauthor{Stolz, Matthews, Cain
}

\begin{abstract}
RIPPEN, Rush Independent Passing Player Efficiency Number, is a new measurement of passer performance. In a simulated world, how would a passer perform starting from their twenty yard line and only performing pass plays? The aspects of each play are simulated using a Bayesian model. This allows rookies and backups with minimal data to be fairly evaluated. Drives would end in a touchdown, field goal or turnover. A player’s RIPPEN is the average number of points they would be expected to score per game. Our metric improves on existing passer rating systems because it is updated to current NFL data, does not weight situational factors, and it is able to be more intuitively understood.

\end{abstract}

\begin{keyword}
\kwd{sports analytics}
\kwd{Bayesian modeling}
\kwd{competitive balance}
\kwd{MCMC}
\end{keyword}

\end{frontmatter}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\input{intro}

%Censoring in rjags
\section{Introduction}
Quantifying the performance of a quarterback is one of the most persistent challenges in sports analytics. While numerous metrics exist, most rely on arbitrary weighting systems or proprietary formulas that lack transparency. In this section, we review the most prominent passer rating systems - NFL Passer Rating, NCAA Passing Efficiency, Total QBR, DVOA, and DYAR - discuss their limitations, and then introduce RIPPEN, a new measure of passer performance.

\subsection{NFL Passer Rating}

The National Football League (NFL) passer rating formula has been the official standard since the 1973 season. Developed by a committee headed by Don Smith and Seymour Siwoff, the metric was designed to compare passers against a fixed performance standard based on data from the 1960-1970 era.

The formula relies on four components: completion percentage, yards per attempt, touchdown percentage, and interception percentage. Each component is calculated independently, bounded by a floor of zero and a cap of 2.375, and then combined using the following formula: 


All of this leads to the NFL formula for passer rating (http://www.nfl.com/help/quarterbackratingformula).  Using the notation from \cite{vanDohlen2011}:
$$
QBR = \left(\frac{\frac{C}{A}-0.3}{0.2} + \frac{\frac{Y}{A}-3}{4} + \frac{\frac{T}{A}}{0.05} + \frac{0.095-\frac{I}{A}}{0.04}\right)\left(\frac{100}{6}\right)
$$
where 
$C$ = Number of Completions\\
$Y$ = Number of Yards\\
$A$ = Number of Attempts\\
$T$ = Number of Touchdowns\\
$I$ = Number of Interceptions\\

This calculation results in a rating between 0 and a maximum of 158.3.

\subsection{NCAA Passer Rating}

College football utilizes a similar but distinct formula known as NCAA Passing Efficiency. Like the NFL metric, it uses completions, yards, touchdowns, and interceptions. However, the NCAA formula does not cap individual components, allowing for a much wider variance in scores. The formula is calculated as:

$$
\frac{8.4Y + 330T + 100C - 200I}{A}
$$
where 
$C$ = Number of Completions\\
$Y$ = Number of Yards\\
$A$ = Number of Attempts\\
$T$ = Number of Touchdowns\\
$I$ = Number of Interceptions\\

Because there are no artificial upper limits on the inputs, the theoretical range of the NCAA rating is significantly wider than the NFL’s, ranging from -731.6 to 1,261.6.

\subsection{Total QBR}
In 2011, ESPN introduced the Total Quarterback Rating (Total QBR) to address the limitations of traditional box-score metrics. Unlike the NFL and NCAA ratings, Total QBR attempts to incorporate contextual elements by utilizing Expected Points Added (EPA). This approach evaluates the difference in expected points before and after a play, rewarding quarterbacks for plays that increase the team's probability of scoring. Total QBR also accounts for rushing contributions, sacks, fumbles, and penalties, and includes adjustments for opponent strength and "garbage time" scenarios.

\subsection{DVOA and DYAR}
Football Outsiders introduced two prominent advanced metrics: Defense-adjusted Value Over Average (DVOA) and Defense-adjusted Yards Above Replacement (DYAR). DVOA measures a quarterback's per-play efficiency by comparing each down and distance situation to a league baseline, subsequently adjusting for the strength of the opposing defense. While DVOA acts as a rate statistic expressed as a percentage above or below the league average, DYAR converts this efficiency into a cumulative volume metric, quantifying the total yards a quarterback contributes over a replacement-level alternative.


\subsection{Criticism of Existing Passer Rating Systems}
Despite their widespread use, existing metrics suffer from significant methodological flaws:
\begin{itemize}
\item Arbitrary Weighting and Caps: The NFL Passer Rating utilizes weights derived from 1970s defensive standards, which are increasingly irrelevant in the modern offensive era. Furthermore, the imposition of a 2.375 cap on component statistics is arbitrary; a quarterback who completes 77.5% of their passes receives the same component score as one who completes 90%.
\item Lack of Interpretability: Both the NFL (0–158.3) and NCAA scales are difficult to interpret intuitively. A difference between a rating of 85 and 95 does not translate to a tangible unit of football value (e.g., points or yards).
\item Lack of Transparency: While Total QBR and DVOA attempt to add context, they are largely "black box" metrics. The exact coefficients, replacement-level baselines, and opponent adjustment formulas for DVOA are proprietary. This lack of transparency makes it impossible for independent researchers to verify, reproduce, or fully audit the results.
\item Contextual Blindness: Traditional passer ratings treat all yards equally. A 10-yard completion on 3rd-and-15 is treated identically to a 10-yard completion on 3rd-and-3, despite the vastly different utility of those outcomes.
\item Complexity: Unlike simple arithmetic formulas, DVOA requires complex play-by-play data parsing and subjective baseline determinations, making it inaccessible for general calculation without specialized databases.
\end{itemize}

\subsection{RIPPEN: A New Measure of Efficiency}

To address these limitations, we propose a new metric: the Rush Independent Passing Player Efficiency Number (RIPPEN). Unlike traditional ratings that rely on linear weights, RIPPEN utilizes a Bayesian model to simulate the distribution of play outcomes for a specific quarterback.

RIPPEN answers a fundamental question: In a simulated world where a team starts on their own 20-yard line and only performs pass plays, how many points would the quarterback be expected to score?

By simulating drive outcomes (Touchdown, Field Goal, or Turnover) based on a quarterback’s specific posterior distributions for completion, yardage, and interception rates, we derive a metric that is both statistically robust and intuitively interpretable. RIPPEN represents the average number of points a player contributes per ten possessions. This metric improves upon existing systems because it is updated dynamically to current NFL data, relies entirely on open-source data and code, and provides a clear, unit-based measure of performance (points per game) rather than an arbitrary index.

\section{Methods}
The idea of this method is to model the distribution of play outcomes from a certain quarterback.  Once we have a model for the ditribution of play outcomes, drives can be simulated based on this distribution.  One could then look at drive outcomes and rate quarterbacks based on a summary of these simulated outcomes.  We refer to this measure as Rush Independent Passing Player Efficiency Number, or RIPPEN, which is formally defined below.  

Drives are simulated using the following rules: 

\begin{itemize}
\item Drive starts on 20 yard line at 1st and 10.  
\item Simulate if the pass was an interception or not. 
\begin{itemize}
\item Yes: Drive ends.  Return 0. 
\item No: Simulate pass.
\end{itemize}
\item Simulate if the pass was complete.  
\begin{itemize}
\item Yes: Simulate yards.
\item No: 0 yards. Update down.
\end{itemize}
\item Simulate Yards
\begin{itemize}
\item Update down and distance to go.  
\end{itemize}
\item This gets repeated until we reach an ending state.
\begin{itemize}
\item Interception: return 0.  
\item Reach 4th down: return 3 with probability a function of the yardage left, 0 otherwise.  
\item Touchdown: return 7. 
\end{itemize}
\end{itemize}

Let the random variables $D_j$ be the value of simulated drive $j$.  $D_j$ takes on values of either 0, 3, or 7, and $\bar{D} = \frac{\sum_j^{n_{s}}D_j}{n_{s}}$ where $n_s$ is the number of simulated drived.  We then define our measure as follows: 

$$
RIPPEN = 10 \bar{D}
$$
.

This can then be interpreted as the average number of points a team would score in ten possessions if their play outcomes were entirely based upon the performance of the quarterback's passing plays.  

\section{Model}
\subsection{Completions}
For a given quarterback over a given period of time, let $n_{comp}$ and $n_{att}$ be the number of completed passes and the number of attempted passes, respectively.  We then have the following Bayesian model for completion percentage: 

$$
n_{comp} \sim Binomial(n_{att}, p_{comp})
$$
with the following prior
$$
p_{comp} \sim \beta(\alpha_c,\beta_c)
$$.

This yields the following posterior distribution for $p_{comp}$: 
$$
p_{comp} |n_{comp}, n_{att} \sim Beta(\alpha_c + n_{comp}, \beta_c +n_{att}-n_{comp})
$$.  

\subsection{Interceptions}
Similarly, for a given quarterback over a given period of time, let $n_{int}$ and $n_{inc}$ be the number of intercepted passes and the number of incomplete passes (interceptions are considered incomplete passes), respectively.  We then have the following Bayesian model for interception percentage given an incomplete pass: 

$$
n_{int} \sim Binomial(n_{inc}, p_{int})
$$
with the following prior
$$
p_{int} \sim Beta(\alpha_i,\beta_i)
$$.
This yields the following posterior distribution for $p_{int}$: 
$$
p_{int} |n_{int},n_{inc} \sim Beta(\alpha_i + n_{int}, \beta_i +n_{inc} - n_i)
$$.  
It is important to note that $p_{int}$ is estimating the probability of an interception given that the pass was incomplete, not the interception rate across all attempted passes.  

In all simulations, we chose to use non-informative priors and set all hyperparameters of these models equal to 1.  Specifically, 

$$
\alpha_c = \beta_c = \alpha_i = \beta_i = 1
$$.  


 (Another possible idea here is to use empircal Bayes where these priors are based on league average completion and interception rates.)


\subsection{Model for yardage given completion}
Let $y_i$ be the yards gained on the $i$-th completed pass, $y_i^{\star} = log(y_i +1)$, and $TD_{i}$ is an indicator equal to 1 if the $i$-th completion is a touchdown and 0 otherwise.  Since we are trying to model yards given a completed pass, we consider touchdowns to be censoring events.  That is, if a player throws a 10 yard touchdown pass, we know that the play we at least ten yards.  This leads to the following likelihood function for modeling yards: 
$$
L(\mu, \sigma^2 | {\bf y}^{\star}) \propto \prod_{i=1}^n f(y_i^{\star}|\mu, \sigma^2)^{1-TD_i} S(y_i^{\star}|\mu, \sigma^2)^{TD_i}
$$
where $f$ is the pdf of a normal distribution and $S$ is the survival function of a normal distribution both with parameters $\mu$ and $\sigma^2$.  

For priors on $\mu$ amd $\sigma^2$, we use: 

$$
\mu \sim Normal(0,10^{6})
$$

$$
\sigma^2 \sim Uniform(0,100)
$$.  











\subsection{Data - Open Source}
\section{Data}
We are using play-by-play data from nflscrapr [MORE DETAILS]

In this pursuit of an understandable and intuitive passer ranking system, it makes sense to use the simplest statistics which surround a quarterback's time on the field. Further, as this strives to remain an open source project, the variables pulled in must remain easily accessible and, likewise, public. For this reason, the data pulled in for each quarterback when all was said and done were completions, yards, interceptions and touchdowns, for each time they were snapped the ball and opted to throw. 

A pleasant duality of this data decision lies within how closely it mirrors the NFL's passer rating formula described above. In so much as this newly improved metric looks to build upon and redefine the NFL's method, it is not an attempt at reinventing the wheel. 
  
    \subsubsection{nflscrapr}

The data used and simulated upon within RIPPEN is scraped from and publically available in another open-source R package, \href{https://github.com/maksimhorowitz/nflscrapR}{\textit{nflscrapr}}. This project pulls, parses, and groups data from the NFL API for easy use. Although many of the added capabilities were not used for this paper, the building block data for our simulations was. Before diving into talk of simulations, the variables gathered should be ironed out and explained. Below is an example of 4 successive rows in our table, from a game between the Steelers and the Colts, one which had "Big Ben" throwing quite well until an interception gave Collins a chance to toss around the old pigskin.

This table houses the name of the quartback, binary variables for whether the pass was complete or imcomplete, intercepted or not, fumbled or not, and an integer value of yards obtained on the play. An interesting subdivision which \textit{nflscrapr} has to offer is the breakdown of TotalYards into "air yards" and "yards after reception". Although future versions of RIPPEN might factor in these variables separately, it was deemed wisest to aggregate them for TotalYards as a good quarterback can be recognized by his ability to pick a receiver in the most advantageous receiving position.



%Let's do this table with knitr so we know where it came from.
<<xtable, results="asis", echo = FALSE>>= 
library(xtable)
nfl <- read.csv(file = "/Users/gregorymatthews/Dropbox/RIPPENgit/data/total09-18_pbp_data.csv")
nfl <- subset(nfl, passer_player_name == "M.Trubisky")
tab <- xtable(nfl[1:4,c("passer_player_name","complete_pass","interception","fumble","air_yards","yards_after_catch")])
print(tab,include.rownames=FALSE)
@
% \begin{center}
% \begin{tabular}{ |c|c|c|c|c|c|  }
%  \hline
%  \multicolumn{5}{|c|}{Sample Data} \\
%  \hline
% Passer & PassOutcome & InterceptionThrown & Fumble & TotalYards\\
%  \hline
% B.Roethlisberger & 1 & 0 & 0 & 5\\
%   \hline
% B.Roethlisberger & 1 & 0 & 0 & 30\\
%   \hline
% B.Roethlisberger & 0 & 1 & 0 & 0\\
%   \hline
% K.Collins & 1 & 0 & 0 & 4 \\
% 
%   \hline
%  \end{tabular}
%  \end{center}

Additionally, solely tracking air yards would hurt the rating of quarterbacks who are effective in deploying a short pitch play to a receiver now open to run 20 yards. Altogether, as RIPPEN looks to capture the effect the throwing quarterback had on the team's state at that moment in the game, these are the variables chosen, simple as they may be. 

\subsection{How we use our data}
  
  Taking this data, broken down by player over seasons we looked to implement a sampling notion, allowing us to build upon our finite examples and imagine a world in which each team put their quarterbacks on the field to throw their hearts out. The only downside to generating this data is that we lose context. Therefore, we needed to structure a proxy measure of whether or not a scoring drive (now just a series of yards gained or imcomplete/intercepted passes) led to a touchdown or a favorable position on the field for a fieldgoal. As such, we need to try to crunch and fit a simulated array of data into a football framework; imposing conditions on successive substrings which, on the field, translate to a continued drive. \\
  
  Looking at our aforementioned data example, let's try to picture what the game looked like assuming there were no rushing plays betwixt our rows. The game starts, more or less on the Steelers' twenty yard line with Roethlisberger's first play resulting in a five yard gain. Therefore, we are at "second and five", with the drive continuing on. Were they not to make ten yards within this "down series", successive first, second, third, and fourth downs, then the drive is over, either resulting in a punt or a field goal attempt. As Ben's next throw is a moderate bomb of thirty yards he does not need to worry about a third down just yet, as the Steelers are back to first down in a brand new down series for the same drive. Great! So now the Steelers are over half-field and looking to put some points on the board, until Ben goes and throws an interception. Regardless of where the current drive and down series state, an interception is an automatic end to the drive, resulting in a returned value of zero points for the quarterback and the team. Hopefully, even if football is a foreign sport to you, this colorful description helped you identify a few criterion a passed array of play results must meet for a drive to stay alive and to identify the drive's down series at any step along the way. 
  
  
    \subsubsection{Simulation! Bayseian?}
    
    With this ability to map decontextualized data into a football framework, RIPPEN is capable of utilizing simulated data; deepening the pool of observations upon which to gauge a quarterback's efficacy. To generate these sampled observations, \textbf{PLEASE SAVE ME}. 
    
    \subsubsection{Markov Chain Notion:}
    
    Formalizing our mapping from raw data into a drive and down series framework requires us to apply some notion of ordering and series-dependency into our array. A prominent way of reworking this into a generalized probability, is through Markov Chains. This matrix allows you to map out the probabilities of moving from one state to another, probabilities which will sum to one as everyone leaving a state must be on their way to another one. After you finish simmering over that metaphysical tidbit, you may recognize that the states are fully contained to any generic down series, with the states randing from first to fourth down. As a drive is mortal and can end with either a failed fouth-down attempt or an interception, we also need to include an absorbing state for a dead drive. For clean rendering, any non-zero or one values are encapsulated in variables which will be described beneath:
\begin{center}
	\begin{tabular}{|c |c c c c c|} 
		\hline
		-Markov- & Down 1 & Down 2 & Down 3 & Down 4 & Over\\ \hline
		Down 1 & a & b & 0 & 0 & c \\ 
		\hline
		Down 2 & d & 0 & e & 0 & f \\
		\hline
		Down 3 & g & 0 & 0 & h & i\\
		\hline
		Down 4 & 0 & 0 & 0 & 1 & j\\
		\hline
		Over & 0 & 0 & 0 & 0 & 1\\
		\hline
	\end{tabular}
	\begin{align*}
	a &= Pr(y_{d,1} > 10)\\
	b &= 1-a\\
	c &= Pr(y_{d,2} > 10 - y_{d,1})\\
	d &= 1 - c\\
	e &= Pr(y_{d,3} > 10 - y_{d,2} - y_{d,1})\\
	f &= 1 - e\\
	g &= \\
	h &= \textbf{Will fill these out in a minute}\\
	i &= \\
	j &= \\
	\end{align*}
\end{center}
  \textbf{Might try to stagger these out by row, making them two or three wide.}\\
  To make sense of the variables above, we need to iron out some notation. As commonly used, \textit{Pr()} stands for the probability that the given value will occur. This makes sense as Markov Chains are our way of generalizing probabilities within any given state. More \textbf{arcane(@luc.edu)} is our notation for the drive state and down: $Pr(y_{d,n} > w)$. This notation captures the probability that the number of yards yielded from down series $d$ and down $n$ will be greater than $w$ yards. As this $y_{d,n}$ notation pervades, we should pin down constraints on $d$ and $n$. As our simulations start the drive on the offensive team's twenty yard line and it takes at least ten yards for a new down series to begin within a drive, $d$ is always an integer ranging from 1 to 8, while the nested $n$ is always contained to the set \{1,2,3,4\}. We also need to account for the ever-present possibility of an interception, an event contained within the $I$ indicator function. 
    \subsubsection{Variable description! (More i's than Mississippi)}

  Dedicated to the variables noted in Markov Chain -- make sense of each one and explain significance.
  
  \begin{enumerate}
  
  \item G: The result of the drive/simulation. Either 7 for TD, 3 for FG or 0 for interception or missed FG. \\
  
  \item I(...): Indicator function: ... \\
  
  \item $C_{d,i}$ ... \\
  
  \item $I_{d,i}$: E[ I(D = 4) ] = P(D = 4) \\
  
  \item $C_{d,i}$: $t'_{1} \cdot M$ = $t'_{2}$ = [$a$  $b$  0  0] \\
  
  \item .... : $t'_{2} \cdot M$ = $t'_{3}$ = [$a^{2}+bc$  $ab$  $bd$  0] \\
  
  \item $$Pr(G_{j} = 3) = Pr(FG \cap (\sum_{i=1}^{n-1} I(D_{n} = 4) = 0 ) \cap (\sum_{i=1}^{n-1} y_{i} < 80 | Q = \sum_{i=1}^{n-1} y_{i})) \cdot P(Q = q)$$ \\ ... Pr(FG $\cap$ Q = q) \\ 
 
  \item $$Pr(G=7) = \sum_{n=1}^{\infty} Pr(\sum_{i = 1}^{n}y_{i} > 80 | \sum_{i=1}^{n}I(D_{i} = 4) = 0) \cdot P(...)$$

\end{enumerate}

\subsection{How we visualize, parse our analyses?}

Idk, Look at other sections of this paper and prep for that. Suppose we could at least speak to breaking it down by season, game, player and whatnot.

\subsection{Theoretical Results}
Do we have any? I guess, in theory, we do?

\textbf{****** end of Rusty's current contributions *****}
\section{Results}




<<echo = FALSE, results = "asis">>=
load("~/Dropbox/RIPPENgit/RIPPEN_2018_season_df.RData")
row.names(rippen2018_season) <- NULL 
#D.Brees       P.Mahomes     R.Fitzpatrick P.Rivers      M.Ryan         J.Goff        T.Brady       D.Watson      R.Wilson      C.Wentz 
rippen2018_season <- rippen2018_season[1:10,]
rippen2018_season$passer_rating <- c(112.9, 112.2, 100.4,102.0, 108.1, 96.4, 95.5, 100.2,110.6, 102.2)
rippen2018_season$TDs <- c(36,36, 17,35,35,33,31,27,36,21)
tab <- xtable(rippen2018_season[1:10,], digits = c(1,NA,2,2,1,0))
caption(tab) <- "Top 10 RIPPEN passers for 2018-19 season"
print(tab, include.rownames = FALSE)
@



%These numbers need to be checked.  
% We should also make this table mor ereproducible.  
\begin{table}[]
  \begin{tabular}{| c | c | c | c | c | c | c |}
    \hline
        & Comp \%. & Yds/Att & TD/Att & Int/Att & QBR & rippen\\
        \hline
        \hline
     T. Brady & 65.8\% & 7.6 & 0.0509 & 0.0193 & 97.7 & 2.688\\
      \hline
     R. Wilson & 65.6\% & 8.1 & \textbf{0.0820} & 0.0164 & 110.9 & 2.583\\
      \hline
      \hline
      J. Allen  & 52.8\% & 6.5 & 0.0313 & 0.037 & 67.9 & 1.445\\
      \hline
      J.Driskel & 59.7\% & 5.7 & 0.034 & \textbf{0.0114} & 82.2 & 1.406\\
      \hline
      \hline
  \end{tabular}
  \end{table}
  
  %These numbers need to be checked too. 
  % I need passer rating numbers checked since they were manually entered.  
  \begin{figure}
  <<echo = FALSE, fig.align='center',fig.width = 6, fig.height= 6, message = FALSE>>=
load("~/Dropbox/RIPPENgit/RIPPEN_2018_season_df.RData")
row.names(rippen2018_season) <- NULL 
 #D.Brees          P.Mahomes        R.Fitzpatrick    P.Rivers          M.Ryan           J.Goff           T.Brady          D.Watson        R.Wilson         C.Wentz          A.Luck           B.Roethlisberger N.Mullens        J.Winston        D.Carr           K.Cousins       N.Foles          B.Mayfield       A.Rodgers        C.Newton        M.Trubisky       D.Prescott       E.Manning        A.Dalton        M.Mariota        J.Garoppolo      A.Smith          M.Stafford       L.Jackson        J.Flacco         S.Darnold        R.Tannehill     C.Keenum         B.Osweiler       C.Beathard       B.Bortles       B.Gabbert        J.Allen          J.Driskel        J.Johnson       J.Rosen          C.Kessler        J.McCown 
rippen2018_season$passer_rating <- c(115.7, 113.8, 100.4,105.5, 108.1, 101.1, 97.7, 103.1,110.9, 102.2,98.7 , 96.5, 90.8, 90.2, 93.9, 99.7, 96.0, 93.7, 97.6, 94.2, 95.4, 96.9, 92.4, 89.6, 92.3, 90.0, 85.7, 89.9,84.5 ,84.2 , 77.6, 92.7, 81.2, 86, 81.8, 79.8, 74.9, 67.9, 82.2, 69.4, 66.7, 77.4, 55.8)
library(ggplot2)
ggplot(aes(x = passer_rating, y = rippen), data = rippen2018_season)  + stat_smooth() + geom_point() + geom_text(aes(label = name),col = rgb(0,0,0,0.5),hjust = "right",data = subset(rippen2018_season, name %in% c("D.Brees","P.Mahomes","T.Brady","R.Fitzpatrick","S.Darnold","B.Gabbert","J.Allen","J.Winston"))) + geom_text(aes(label = name),col = rgb(0,0,0,0.5),hjust = "left",data = subset(rippen2018_season, name %in% c("R.Wilson","J.Driskel","J.McCown","C.Kessler", "R.Tannehill"))) 


# plot(rippen2018_season$passer_rating,rippen2018_season$rippen, pch = 16, xlab = "Passer Rating", ylab = "rippen")
# #text(rippen2018_season$passer_rating,rippen2018_season$rippen,rippen2018_season$name,pos = 3)
# text(rippen2018_season$passer_rating[9],rippen2018_season$rippen[9],rippen2018_season$name[9],pos = 3)
# text(rippen2018_season$passer_rating[7],rippen2018_season$rippen[7],rippen2018_season$name[7],pos = 2)
# text(rippen2018_season$passer_rating[3],rippen2018_season$rippen[3],rippen2018_season$name[3],pos = 2)
# text(rippen2018_season$passer_rating[1],rippen2018_season$rippen[1],rippen2018_season$name[1],pos = 2)
# text(rippen2018_season$passer_rating[2],rippen2018_season$rippen[2],rippen2018_season$name[2],pos = 2)
# text(rippen2018_season$passer_rating[43],rippen2018_season$rippen[43],rippen2018_season$name[43],pos = 4)
# text(rippen2018_season$passer_rating[38],rippen2018_season$rippen[38],rippen2018_season$name[38],pos = 4)
# 
# text(rippen2018_season$passer_rating[39],rippen2018_season$rippen[39],rippen2018_season$name[39],pos = 4)
# text(rippen2018_season$passer_rating[42],rippen2018_season$rippen[42],rippen2018_season$name[42],pos = 4)
@
\caption{Comparing passer rating and RIPPEN for the 2018 season}
\end{figure}


%We need to label come interesting points on here. 
<<echo = FALSE, fig.width = 6, fig.height= 6, message = FALSE, warning=FALSE>>=
library(plotly)
library(ggplot2)
load("~/Dropbox/RIPPENgit/results_season_2018.RData")
dist <- data.frame(do.call(rbind,lapply(results[["2018"]],table)))
dist$rippen <- 7*dist$X7/50000+3*dist$X3/50000
dist$X0 <- dist$X0/50000 
dist$X3 <- dist$X3/50000 
dist$X7 <- dist$X7/50000 
dist$name <- row.names(dist)

gg <- ggplot(aes(x = X7, y = X3, label = name ,colour = rippen),data = dist) + geom_point() + geom_abline(slope = rep(-7/3,4), intercept = c(1/3,2/3,3/3,4/3)) + scale_colour_gradient(high = "#D44500",low = "darkblue") + xlab("Probability of Touchdown") + ylab("Probability of Field Goal") + geom_text(aes(label = ifelse(name %in% c("D.Brees","P.Mahomes","M.Glennon","M.Barkley","C.Henne","M.Schaub","M.Sanchez","A.Rodgers","C.Kessler","M.Ryan","C.McCoy","D.Kizer","J. Allen"),name,'')), hjust = 0, vjust = 0) + xlim(0, 0.55)
gg

#ggplotly(gg, tooltip = c("label","colour"))
@

\subsection{Correlation between RIPPEN and winning}
Compare RIPPEN and winning to QBR and winning.  

\subsection{Preliminary Results \& Notes}

\subsection{Bayesian Posterior Distributions Stuff}
What do the posterior parameters look like? 

\subsection{Rodgers vs Tebow Example. }

\subsection{Distribtuion of RIPPEN}

\subsection{Best Games/Seasons}

\section{Conclusion and Future Work}
RIPPEN is good.  We will do more eventually.  

Adding a defensive adjustment.  


Do we even want to add these things?  
How do we deal with pass interference?  
Defensive Holding? 
Sacks? Add another layer.  
Fumbles? Could treat similar to interceptions? 
Should interceptions ever result in negative numbers?  
How do we assign the negative numbers for interceptions?  
\section{Appendix}

<<echo = FALSE, results = "asis">>=
load("~/Dropbox/RIPPENgit/RIPPEN_2018_season_df.RData")
row.names(rippen2018_season) <- NULL 
#D.Brees       P.Mahomes     R.Fitzpatrick P.Rivers      M.Ryan         J.Goff        T.Brady       D.Watson      R.Wilson      C.Wentz 
#rippen2018_season <- rippen2018_season
#rippen2018_season$passer_rating <- c(112.9, 112.2, 100.4,102.0, 108.1, 96.4, 95.5, 100.2,110.6, 102.2)
#rippen2018_season$TDs <- c(36,36, 17,35,35,33,31,27,36,21)
tab <- xtable(rippen2018_season)
caption(tab) <- "Top 10 RIPPEN passers for 2018-19 season"
print(tab)
@



\bibliographystyle{imsart-nameyear}
\bibliography{refs}

\href{http://bleacherreport.com/articles/889199-big-flaws-in-espns-total-qbr-exposed-after-tim-tebow-rates-above-aaron-rodgers}{Tim Tebow example of why QBR is bad:}\\

Read more about this \href{https://412sportsanalytics.wordpress.com/2016/10/05/pareto-frontier-and-non-dominated-quarterbacks/}{(pareto-frontier)}.  Might be interesting

- Would we add something like this to our results\\

\href{https://www.footballoutsiders.com/stats/qb}{DYAR and DVOA:}\\


\href{http://www.nih.ticz.musclehedz.charlespoliquin.sportsci.org/2011/mep.htm}{nih: charles poliquin}\\


\href{https://www.degruyter.com/view/j/jqas.2011.7.3/jqas.2011.7.3.1359/jqas.2011.7.3.1359.xml?format=INT}{JQAS}\\

\href{https://www.profootballhof.com/news/nfl-s-passer-rating/}{NFL Passer rating:}\\

\href{http://www.donsteinberg.com/qbrating.htm}{Don Steinberg: How I Learned to Stop Worrying and Love the Bomb}\\

\href{http://www.espn.com/blog/statsinfo/post/\_/id/123701/how-is-total-qbr-calculated-we-explain-our-quarterback-rating}{Total QBR calculation:}\\

http://www.math.montana.edu/graduate/writing-projects/2017/Gomez17.pdf

A Statistical Analysis of NFL Quarterback Rating Variables\\
Derek Stimel, Journal of Quantitative Analysis in Sports\\
\hfill\\
The Quarterback Prediction Problem: Forecasting the Performance of College Quarterbacks Selected in the NFL Draft\\
Julian Wolfson et al., Journal of Quantitative Analysis in Sports\\
\hfill\\
Analyzing dependence matrices to investigate relationships between national football 
league combine event performances\\
Brook T. Russell et al., Journal of Quantitative Analysis in Sports\\
\hfill\\
Isolating the Effect of Individual Linemen on the Passing Game in the National Football League\\
Benjamin C Alamar et al., Journal of Quantitative Analysis in Sports\\
\hfill\\
Quantifying NFL Coaching: A Proof of New Growth Theory\\
Kevin P. Braig, Journal of Quantitative Analysis in Sports\\

CITE Passer Rating\\
CITE QBR\\

\href{http://www.donsteinberg.com/qbrating.htm}{Don Steinberg: How I Learned to Stop Worrying and Love the Bomb}\\

\href{http://www.nfl.com/help/quarterbackratingformula}{Quarterback Rating:}\\

\href{https://www.profootballhof.com/news/nfl-s-passer-rating/}{NFL Passer rating:}\\

\href{http://football.stassen.com/pass-eff/}{College Passer efficiency:}\\

\href{https://www.si.com/more-sports/2011/08/03/defending-qb-rating}{Defending Passer rating: Kerry Byrne}\\

\href{https://www.nytimes.com/2004/01/14/sports/pro-football-the-nfl-s-passer-rating-arcane-and-misunderstood.html}{PRO FOOTBALL; The N.F.L.'s Passer Rating, Arcane and Misunderstood}\\

\subsubsection{Criticism of QBR}
Arbitrary scale (0 to 158.3??)
Hard to interpret (What does 121.6 mean?)
QBR overly credits QBs for scoring TDs -- discuss whether or not this is entirely wrong. Something to be said for "getting er done", but they weight this a bit too much for a metric which assesses QB efficacy.
\begin{quote}
[Don] Smith thought it would be more meaningful if an excellent score came to around 100, just like in school. "I think our attitude was that 100 was an A," he recalls. "And anything above 100, that was an A-plus." So, in a move that made sense at the time and has had everyone else confused for three decades, he multiplied the raw total by 100 and divided by 6, turning a statistically average performance -- 1s across the board -- into 66.7. It also made the maximum rating a ridiculous 158.2.
(http://www.donsteinberg.com/qbrating.htm)
\end{quote}

\end{document}
